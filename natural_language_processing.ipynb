{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a504f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "045467fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pipeline in module transformers.pipelines:\n",
      "\n",
      "pipeline(task: Optional[str] = None, model: Union[str, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel'), NoneType] = None, config: Union[str, transformers.configuration_utils.PretrainedConfig, NoneType] = None, tokenizer: Union[str, transformers.tokenization_utils.PreTrainedTokenizer, ForwardRef('PreTrainedTokenizerFast'), NoneType] = None, feature_extractor: Union[str, ForwardRef('SequenceFeatureExtractor'), NoneType] = None, image_processor: Union[str, transformers.image_processing_utils.BaseImageProcessor, NoneType] = None, processor: Union[str, transformers.processing_utils.ProcessorMixin, NoneType] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Union[str, bool, NoneType] = None, device: Union[int, str, ForwardRef('torch.device'), NoneType] = None, device_map: Union[str, dict[str, Union[int, str]], NoneType] = None, torch_dtype: Union[str, ForwardRef('torch.dtype'), NoneType] = 'auto', trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> transformers.pipelines.base.Pipeline\n",
      "    Utility factory method to build a [`Pipeline`].\n",
      "    \n",
      "    A pipeline consists of:\n",
      "    \n",
      "        - One or more components for pre-processing model inputs, such as a [tokenizer](tokenizer),\n",
      "        [image_processor](image_processor), [feature_extractor](feature_extractor), or [processor](processors).\n",
      "        - A [model](model) that generates predictions from the inputs.\n",
      "        - Optional post-processing steps to refine the model's output, which can also be handled by processors.\n",
      "    \n",
      "    <Tip>\n",
      "    While there are such optional arguments as `tokenizer`, `feature_extractor`, `image_processor`, and `processor`,\n",
      "    they shouldn't be specified all at once. If these components are not provided, `pipeline` will try to load\n",
      "    required ones automatically. In case you want to provide these components explicitly, please refer to a\n",
      "    specific pipeline in order to get more details regarding what components are required.\n",
      "    </Tip>\n",
      "    \n",
      "    Args:\n",
      "        task (`str`):\n",
      "            The task defining which pipeline will be returned. Currently accepted tasks are:\n",
      "    \n",
      "            - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n",
      "            - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n",
      "            - `\"depth-estimation\"`: will return a [`DepthEstimationPipeline`].\n",
      "            - `\"document-question-answering\"`: will return a [`DocumentQuestionAnsweringPipeline`].\n",
      "            - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n",
      "            - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n",
      "            - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n",
      "            - `\"image-feature-extraction\"`: will return an [`ImageFeatureExtractionPipeline`].\n",
      "            - `\"image-segmentation\"`: will return a [`ImageSegmentationPipeline`].\n",
      "            - `\"image-text-to-text\"`: will return a [`ImageTextToTextPipeline`].\n",
      "            - `\"image-to-image\"`: will return a [`ImageToImagePipeline`].\n",
      "            - `\"image-to-text\"`: will return a [`ImageToTextPipeline`].\n",
      "            - `\"mask-generation\"`: will return a [`MaskGenerationPipeline`].\n",
      "            - `\"object-detection\"`: will return a [`ObjectDetectionPipeline`].\n",
      "            - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n",
      "            - `\"summarization\"`: will return a [`SummarizationPipeline`].\n",
      "            - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n",
      "            - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n",
      "            - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n",
      "              [`TextClassificationPipeline`].\n",
      "            - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n",
      "            - `\"text-to-audio\"` (alias `\"text-to-speech\"` available): will return a [`TextToAudioPipeline`]:.\n",
      "            - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n",
      "            - `\"translation\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"video-classification\"`: will return a [`VideoClassificationPipeline`].\n",
      "            - `\"visual-question-answering\"`: will return a [`VisualQuestionAnsweringPipeline`].\n",
      "            - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n",
      "            - `\"zero-shot-image-classification\"`: will return a [`ZeroShotImageClassificationPipeline`].\n",
      "            - `\"zero-shot-audio-classification\"`: will return a [`ZeroShotAudioClassificationPipeline`].\n",
      "            - `\"zero-shot-object-detection\"`: will return a [`ZeroShotObjectDetectionPipeline`].\n",
      "    \n",
      "        model (`str` or [`PreTrainedModel`] or [`TFPreTrainedModel`], *optional*):\n",
      "            The model that will be used by the pipeline to make predictions. This can be a model identifier or an\n",
      "            actual instance of a pretrained model inheriting from [`PreTrainedModel`] (for PyTorch) or\n",
      "            [`TFPreTrainedModel`] (for TensorFlow).\n",
      "    \n",
      "            If not provided, the default for the `task` will be loaded.\n",
      "        config (`str` or [`PretrainedConfig`], *optional*):\n",
      "            The configuration that will be used by the pipeline to instantiate the model. This can be a model\n",
      "            identifier or an actual pretrained model configuration inheriting from [`PretrainedConfig`].\n",
      "    \n",
      "            If not provided, the default configuration file for the requested model will be used. That means that if\n",
      "            `model` is given, its default configuration will be used. However, if `model` is not supplied, this\n",
      "            `task`'s default model's config is used instead.\n",
      "        tokenizer (`str` or [`PreTrainedTokenizer`], *optional*):\n",
      "            The tokenizer that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained tokenizer inheriting from [`PreTrainedTokenizer`].\n",
      "    \n",
      "            If not provided, the default tokenizer for the given `model` will be loaded (if it is a string). If `model`\n",
      "            is not specified or not a string, then the default tokenizer for `config` is loaded (if it is a string).\n",
      "            However, if `config` is also not given or not a string, then the default tokenizer for the given `task`\n",
      "            will be loaded.\n",
      "        feature_extractor (`str` or [`PreTrainedFeatureExtractor`], *optional*):\n",
      "            The feature extractor that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained feature extractor inheriting from [`PreTrainedFeatureExtractor`].\n",
      "    \n",
      "            Feature extractors are used for non-NLP models, such as Speech or Vision models as well as multi-modal\n",
      "            models. Multi-modal models will also require a tokenizer to be passed.\n",
      "    \n",
      "            If not provided, the default feature extractor for the given `model` will be loaded (if it is a string). If\n",
      "            `model` is not specified or not a string, then the default feature extractor for `config` is loaded (if it\n",
      "            is a string). However, if `config` is also not given or not a string, then the default feature extractor\n",
      "            for the given `task` will be loaded.\n",
      "        image_processor (`str` or [`BaseImageProcessor`], *optional*):\n",
      "            The image processor that will be used by the pipeline to preprocess images for the model. This can be a\n",
      "            model identifier or an actual image processor inheriting from [`BaseImageProcessor`].\n",
      "    \n",
      "            Image processors are used for Vision models and multi-modal models that require image inputs. Multi-modal\n",
      "            models will also require a tokenizer to be passed.\n",
      "    \n",
      "            If not provided, the default image processor for the given `model` will be loaded (if it is a string). If\n",
      "            `model` is not specified or not a string, then the default image processor for `config` is loaded (if it is\n",
      "            a string).\n",
      "        processor (`str` or [`ProcessorMixin`], *optional*):\n",
      "            The processor that will be used by the pipeline to preprocess data for the model. This can be a model\n",
      "            identifier or an actual processor inheriting from [`ProcessorMixin`].\n",
      "    \n",
      "            Processors are used for multi-modal models that require multi-modal inputs, for example, a model that\n",
      "            requires both text and image inputs.\n",
      "    \n",
      "            If not provided, the default processor for the given `model` will be loaded (if it is a string). If `model`\n",
      "            is not specified or not a string, then the default processor for `config` is loaded (if it is a string).\n",
      "        framework (`str`, *optional*):\n",
      "            The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
      "            installed.\n",
      "    \n",
      "            If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
      "            both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
      "            provided.\n",
      "        revision (`str`, *optional*, defaults to `\"main\"`):\n",
      "            When passing a task name or a string model identifier: The specific model version to use. It can be a\n",
      "            branch name, a tag name, or a commit id, since we use a git-based system for storing models and other\n",
      "            artifacts on huggingface.co, so `revision` can be any identifier allowed by git.\n",
      "        use_fast (`bool`, *optional*, defaults to `True`):\n",
      "            Whether or not to use a Fast tokenizer if possible (a [`PreTrainedTokenizerFast`]).\n",
      "        use_auth_token (`str` or *bool*, *optional*):\n",
      "            The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n",
      "            when running `huggingface-cli login` (stored in `~/.huggingface`).\n",
      "        device (`int` or `str` or `torch.device`):\n",
      "            Defines the device (*e.g.*, `\"cpu\"`, `\"cuda:1\"`, `\"mps\"`, or a GPU ordinal rank like `1`) on which this\n",
      "            pipeline will be allocated.\n",
      "        device_map (`str` or `dict[str, Union[int, str, torch.device]`, *optional*):\n",
      "            Sent directly as `model_kwargs` (just a simpler shortcut). When `accelerate` library is present, set\n",
      "            `device_map=\"auto\"` to compute the most optimized `device_map` automatically (see\n",
      "            [here](https://huggingface.co/docs/accelerate/main/en/package_reference/big_modeling#accelerate.cpu_offload)\n",
      "            for more information).\n",
      "    \n",
      "            <Tip warning={true}>\n",
      "    \n",
      "            Do not use `device_map` AND `device` at the same time as they will conflict\n",
      "    \n",
      "            </Tip>\n",
      "    \n",
      "        torch_dtype (`str` or `torch.dtype`, *optional*):\n",
      "            Sent directly as `model_kwargs` (just a simpler shortcut) to use the available precision for this model\n",
      "            (`torch.float16`, `torch.bfloat16`, ... or `\"auto\"`).\n",
      "        trust_remote_code (`bool`, *optional*, defaults to `False`):\n",
      "            Whether or not to allow for custom code defined on the Hub in their own modeling, configuration,\n",
      "            tokenization or even pipeline files. This option should only be set to `True` for repositories you trust\n",
      "            and in which you have read the code, as it will execute code present on the Hub on your local machine.\n",
      "        model_kwargs (`dict[str, Any]`, *optional*):\n",
      "            Additional dictionary of keyword arguments passed along to the model's `from_pretrained(...,\n",
      "            **model_kwargs)` function.\n",
      "        kwargs (`dict[str, Any]`, *optional*):\n",
      "            Additional keyword arguments passed along to the specific pipeline init (see the documentation for the\n",
      "            corresponding pipeline class for possible values).\n",
      "    \n",
      "    Returns:\n",
      "        [`Pipeline`]: A suitable pipeline for the task.\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    ```python\n",
      "    >>> from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
      "    \n",
      "    >>> # Sentiment analysis pipeline\n",
      "    >>> analyzer = pipeline(\"sentiment-analysis\")\n",
      "    \n",
      "    >>> # Question answering pipeline, specifying the checkpoint identifier\n",
      "    >>> oracle = pipeline(\n",
      "    ...     \"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\", tokenizer=\"google-bert/bert-base-cased\"\n",
      "    ... )\n",
      "    \n",
      "    >>> # Named entity recognition pipeline, passing in a specific model and tokenizer\n",
      "    >>> model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
      "    >>> tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
      "    >>> recognizer = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0d0f741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/model.safetensors\n",
      "Since the `torch_dtype` attribute can't be found in model's config object, will use torch_dtype={torch_dtype} as derived from model's weights\n",
      "Instantiating DistilBertForSequenceClassification model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(task='text-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a12b50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9566315412521362}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"This restaurant is ok, but the service is terrible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f60f1924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--ProsusAI--finbert/snapshots/4556d13015211d73dccd3fdd39d39232506f3e43/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"positive\",\n",
      "    \"1\": \"negative\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 1,\n",
      "    \"neutral\": 2,\n",
      "    \"positive\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--ProsusAI--finbert/snapshots/4556d13015211d73dccd3fdd39d39232506f3e43/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"positive\",\n",
      "    \"1\": \"negative\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 1,\n",
      "    \"neutral\": 2,\n",
      "    \"positive\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/pcnslt/.cache/huggingface/hub/models--ProsusAI--finbert/snapshots/4556d13015211d73dccd3fdd39d39232506f3e43/pytorch_model.bin\n",
      "Attempting to create safetensors variant\n",
      "Since the `torch_dtype` attribute can't be found in model's config object, will use torch_dtype={torch_dtype} as derived from model's weights\n",
      "Instantiating BertForSequenceClassification model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ProsusAI/finbert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--ProsusAI--finbert/snapshots/4556d13015211d73dccd3fdd39d39232506f3e43/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"positive\",\n",
      "    \"1\": \"negative\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 1,\n",
      "    \"neutral\": 2,\n",
      "    \"positive\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/pcnslt/.cache/huggingface/hub/models--ProsusAI--finbert/snapshots/4556d13015211d73dccd3fdd39d39232506f3e43/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--ProsusAI--finbert/snapshots/4556d13015211d73dccd3fdd39d39232506f3e43/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--ProsusAI--finbert/snapshots/4556d13015211d73dccd3fdd39d39232506f3e43/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--ProsusAI--finbert/snapshots/4556d13015211d73dccd3fdd39d39232506f3e43/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"positive\",\n",
      "    \"1\": \"negative\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 1,\n",
      "    \"neutral\": 2,\n",
      "    \"positive\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Safetensors PR exists\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--ProsusAI--finbert/snapshots/4556d13015211d73dccd3fdd39d39232506f3e43/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"positive\",\n",
      "    \"1\": \"negative\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 1,\n",
      "    \"neutral\": 2,\n",
      "    \"positive\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe_fin_text = pipeline(task='text-classification', model = 'ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55d23e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.9537850022315979}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_fin_text('The president has put increased tariffs on this product, which will increase company spending, hence hurting the company financials.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "516ead03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\"This stock is going up.\", \"We will be holding the bag for a while on this one.\",\n",
    "          \"I'm still analyzing this stock.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6f2c680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.5659778714179993},\n",
       " {'label': 'neutral', 'score': 0.9039294123649597},\n",
       " {'label': 'neutral', 'score': 0.8784329891204834}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_fin_text(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "212da61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--dbmdz--bert-large-cased-finetuned-conll03-english/snapshots/4c534963167c08d4b8ff1f88733cf2930f86add0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_num_labels\": 9,\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-MISC\",\n",
      "    \"2\": \"I-MISC\",\n",
      "    \"3\": \"B-PER\",\n",
      "    \"4\": \"I-PER\",\n",
      "    \"5\": \"B-ORG\",\n",
      "    \"6\": \"I-ORG\",\n",
      "    \"7\": \"B-LOC\",\n",
      "    \"8\": \"I-LOC\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"B-LOC\": 7,\n",
      "    \"B-MISC\": 1,\n",
      "    \"B-ORG\": 5,\n",
      "    \"B-PER\": 3,\n",
      "    \"I-LOC\": 8,\n",
      "    \"I-MISC\": 2,\n",
      "    \"I-ORG\": 6,\n",
      "    \"I-PER\": 4,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--dbmdz--bert-large-cased-finetuned-conll03-english/snapshots/4c534963167c08d4b8ff1f88733cf2930f86add0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_num_labels\": 9,\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-MISC\",\n",
      "    \"2\": \"I-MISC\",\n",
      "    \"3\": \"B-PER\",\n",
      "    \"4\": \"I-PER\",\n",
      "    \"5\": \"B-ORG\",\n",
      "    \"6\": \"I-ORG\",\n",
      "    \"7\": \"B-LOC\",\n",
      "    \"8\": \"I-LOC\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"B-LOC\": 7,\n",
      "    \"B-MISC\": 1,\n",
      "    \"B-ORG\": 5,\n",
      "    \"B-PER\": 3,\n",
      "    \"I-LOC\": 8,\n",
      "    \"I-MISC\": 2,\n",
      "    \"I-ORG\": 6,\n",
      "    \"I-PER\": 4,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/pcnslt/.cache/huggingface/hub/models--dbmdz--bert-large-cased-finetuned-conll03-english/snapshots/4c534963167c08d4b8ff1f88733cf2930f86add0/model.safetensors\n",
      "Since the `torch_dtype` attribute can't be found in model's config object, will use torch_dtype={torch_dtype} as derived from model's weights\n",
      "Instantiating BertForTokenClassification model under default dtype torch.float32.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--dbmdz--bert-large-cased-finetuned-conll03-english/snapshots/4c534963167c08d4b8ff1f88733cf2930f86add0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_num_labels\": 9,\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-MISC\",\n",
      "    \"2\": \"I-MISC\",\n",
      "    \"3\": \"B-PER\",\n",
      "    \"4\": \"I-PER\",\n",
      "    \"5\": \"B-ORG\",\n",
      "    \"6\": \"I-ORG\",\n",
      "    \"7\": \"B-LOC\",\n",
      "    \"8\": \"I-LOC\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"B-LOC\": 7,\n",
      "    \"B-MISC\": 1,\n",
      "    \"B-ORG\": 5,\n",
      "    \"B-PER\": 3,\n",
      "    \"I-LOC\": 8,\n",
      "    \"I-MISC\": 2,\n",
      "    \"I-ORG\": 6,\n",
      "    \"I-PER\": 4,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/pcnslt/.cache/huggingface/hub/models--dbmdz--bert-large-cased-finetuned-conll03-english/snapshots/4c534963167c08d4b8ff1f88733cf2930f86add0/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--dbmdz--bert-large-cased-finetuned-conll03-english/snapshots/4c534963167c08d4b8ff1f88733cf2930f86add0/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--dbmdz--bert-large-cased-finetuned-conll03-english/snapshots/4c534963167c08d4b8ff1f88733cf2930f86add0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_num_labels\": 9,\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-MISC\",\n",
      "    \"2\": \"I-MISC\",\n",
      "    \"3\": \"B-PER\",\n",
      "    \"4\": \"I-PER\",\n",
      "    \"5\": \"B-ORG\",\n",
      "    \"6\": \"I-ORG\",\n",
      "    \"7\": \"B-LOC\",\n",
      "    \"8\": \"I-LOC\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"B-LOC\": 7,\n",
      "    \"B-MISC\": 1,\n",
      "    \"B-ORG\": 5,\n",
      "    \"B-PER\": 3,\n",
      "    \"I-LOC\": 8,\n",
      "    \"I-MISC\": 2,\n",
      "    \"I-ORG\": 6,\n",
      "    \"I-PER\": 4,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--dbmdz--bert-large-cased-finetuned-conll03-english/snapshots/4c534963167c08d4b8ff1f88733cf2930f86add0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_num_labels\": 9,\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-MISC\",\n",
      "    \"2\": \"I-MISC\",\n",
      "    \"3\": \"B-PER\",\n",
      "    \"4\": \"I-PER\",\n",
      "    \"5\": \"B-ORG\",\n",
      "    \"6\": \"I-ORG\",\n",
      "    \"7\": \"B-LOC\",\n",
      "    \"8\": \"I-LOC\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"B-LOC\": 7,\n",
      "    \"B-MISC\": 1,\n",
      "    \"B-ORG\": 5,\n",
      "    \"B-PER\": 3,\n",
      "    \"I-LOC\": 8,\n",
      "    \"I-MISC\": 2,\n",
      "    \"I-ORG\": 6,\n",
      "    \"I-PER\": 4,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe_ner_named_entity_recognition = pipeline(task='ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69b0651b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-MISC',\n",
       "  'score': np.float32(0.7549945),\n",
       "  'index': 7,\n",
       "  'word': 'C',\n",
       "  'start': 29,\n",
       "  'end': 30},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.44494963),\n",
       "  'index': 8,\n",
       "  'word': '##line',\n",
       "  'start': 30,\n",
       "  'end': 34},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.9996511),\n",
       "  'index': 16,\n",
       "  'word': 'Delta',\n",
       "  'start': 63,\n",
       "  'end': 68},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.9990067),\n",
       "  'index': 17,\n",
       "  'word': 'Airlines',\n",
       "  'start': 69,\n",
       "  'end': 77}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_ner_named_entity_recognition(\"The first time I heard about Cline was a tool when I worked at Delta Airlines.  It was so amazing, because it created all the code and the file itself.  And it was much cheaper than other competitors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d99623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-cased-distilled-squad/snapshots/564e9b582944a57a3e586bbb98fd6f0a4118db7f/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-cased-distilled-squad/snapshots/564e9b582944a57a3e586bbb98fd6f0a4118db7f/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-cased-distilled-squad/snapshots/564e9b582944a57a3e586bbb98fd6f0a4118db7f/model.safetensors\n",
      "Since the `torch_dtype` attribute can't be found in model's config object, will use torch_dtype={torch_dtype} as derived from model's weights\n",
      "Instantiating DistilBertForQuestionAnswering model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing DistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of DistilBertForQuestionAnswering were initialized from the model checkpoint at distilbert/distilbert-base-cased-distilled-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForQuestionAnswering for predictions without further training.\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-cased-distilled-squad/snapshots/564e9b582944a57a3e586bbb98fd6f0a4118db7f/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-cased-distilled-squad/snapshots/564e9b582944a57a3e586bbb98fd6f0a4118db7f/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-cased-distilled-squad/snapshots/564e9b582944a57a3e586bbb98fd6f0a4118db7f/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-cased-distilled-squad/snapshots/564e9b582944a57a3e586bbb98fd6f0a4118db7f/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--distilbert--distilbert-base-cased-distilled-squad/snapshots/564e9b582944a57a3e586bbb98fd6f0a4118db7f/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe_question_answer_bot = pipeline(task='question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bf83724",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_text = \"\"\"\n",
    "From July 4 through July 7, 2025, a destructive and deadly flood took place in the Texas Hill Country, particularly in Kerr County, in the U.S. state of Texas. During the flooding, water levels along the Guadalupe River rose quickly and significantly when 5–11 in (130–280 mm) of rain fell in a short amount of time. As a result, at least 120 fatalities have been confirmed, of which at least 96 are in Kerr County, with more than 173 reported missing. The flooding was caused by a mesoscale convective vortex partially fed by the remnants of Tropical Storm Barry.                         \n",
    "                         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82cab374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.42123496532440186,\n",
       " 'start': 84,\n",
       " 'end': 102,\n",
       " 'answer': 'Texas Hill Country'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_question_answer_bot(question=\"Where did the flood happen?\", context=context_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "052e8bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb22de4e77bd4aa3a8a7d50ada48cfeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--google-t5--t5-base/snapshots/a9723ea7f1b39c1eae772870f3b547bf6ef7e6c1/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--google-t5--t5-base/snapshots/a9723ea7f1b39c1eae772870f3b547bf6ef7e6c1/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de729c138daa4e2a8b3781619f1fa955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file model.safetensors from cache at /Users/pcnslt/.cache/huggingface/hub/models--google-t5--t5-base/snapshots/a9723ea7f1b39c1eae772870f3b547bf6ef7e6c1/model.safetensors\n",
      "Since the `torch_dtype` attribute can't be found in model's config object, will use torch_dtype={torch_dtype} as derived from model's weights\n",
      "Instantiating T5ForConditionalGeneration model under default dtype torch.float32.\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at google-t5/t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088cbc8126ef4ba18477836781df4ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file generation_config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--google-t5--t5-base/snapshots/a9723ea7f1b39c1eae772870f3b547bf6ef7e6c1/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--google-t5--t5-base/snapshots/a9723ea7f1b39c1eae772870f3b547bf6ef7e6c1/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a736872ec234795b8757e15d26eec49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4148374c13f949ccb8fa2408fd2eb136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model from cache at /Users/pcnslt/.cache/huggingface/hub/models--google-t5--t5-base/snapshots/a9723ea7f1b39c1eae772870f3b547bf6ef7e6c1/spiece.model\n",
      "loading file tokenizer.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--google-t5--t5-base/snapshots/a9723ea7f1b39c1eae772870f3b547bf6ef7e6c1/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /Users/pcnslt/.cache/huggingface/hub/models--google-t5--t5-base/snapshots/a9723ea7f1b39c1eae772870f3b547bf6ef7e6c1/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.53.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe_translate = pipeline(task='translation_en_to_de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "606a7e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Ich möchte diesen Satz in eine andere Sprache übersetzen.'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_translate(\"I want to translate this sentence to another language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579c803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
